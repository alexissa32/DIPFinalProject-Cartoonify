{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our dataset: http://pascal.inrialpes.fr/data/human/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in image and detect face(s), https://realpython.com/face-recognition-with-python/ (need adjust size of squares to include hair)\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "TEST_PHOTO = \"../INRIAPerson/Train/pos/crop001554.png\"\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(TEST_PHOTO)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=3,\n",
    "    minSize=(25, 25),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE #https://stackoverflow.com/questions/41341409/where-is-cv-haar-scale-image-in-opencv-3-1-0-with-python-3-5\n",
    ")\n",
    "\n",
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 200 39 39\n"
     ]
    }
   ],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "    print(x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(TEST_PHOTO)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x+10, y-5), (x+10+w, y-5+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(TEST_PHOTO)\n",
    "cv2.imwrite('roi.png', image[y-5:y-5+h, x+10:x+10+w]) #https://stackoverflow.com/questions/9084609/how-to-copy-a-image-region-using-opencv-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Alex Issa\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Add, Conv2D, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
    "\n",
    "def edsr(scale, num_filters=64, num_res_blocks=8, res_block_scaling=None):\n",
    "    \"\"\"Creates an EDSR model.\"\"\"\n",
    "    x_in = Input(shape=(None, None, 3))\n",
    "    x = Lambda(normalize)(x_in)\n",
    "\n",
    "    x = b = Conv2D(num_filters, 3, padding='same')(x)\n",
    "    for i in range(num_res_blocks):\n",
    "        b = res_block(b, num_filters, res_block_scaling)\n",
    "    b = Conv2D(num_filters, 3, padding='same')(b)\n",
    "    x = Add()([x, b])\n",
    "\n",
    "    x = upsample(x, scale, num_filters)\n",
    "    x = Conv2D(3, 3, padding='same')(x)\n",
    "\n",
    "    x = Lambda(denormalize)(x)\n",
    "    return Model(x_in, x, name=\"edsr\")\n",
    "\n",
    "\n",
    "def res_block(x_in, filters, scaling):\n",
    "    \"\"\"Creates an EDSR residual block.\"\"\"\n",
    "    x = Conv2D(filters, 3, padding='same', activation='relu')(x_in)\n",
    "    x = Conv2D(filters, 3, padding='same')(x)\n",
    "    if scaling:\n",
    "        x = Lambda(lambda t: t * scaling)(x)\n",
    "    x = Add()([x_in, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsample(x, scale, num_filters):\n",
    "    def upsample_1(x, factor, **kwargs):\n",
    "        \"\"\"Sub-pixel convolution.\"\"\"\n",
    "        x = Conv2D(num_filters * (factor ** 2), 3, padding='same', **kwargs)(x)\n",
    "        return Lambda(pixel_shuffle(scale=factor))(x)\n",
    "\n",
    "    if scale == 2:\n",
    "        x = upsample_1(x, 2, name='conv2d_1_scale_2')\n",
    "    elif scale == 3:\n",
    "        x = upsample_1(x, 3, name='conv2d_1_scale_3')\n",
    "    elif scale == 4:\n",
    "        x = upsample_1(x, 2, name='conv2d_1_scale_2')\n",
    "        x = upsample_1(x, 2, name='conv2d_2_scale_2')\n",
    "\n",
    "    return x\n",
    "\n",
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - DIV2K_RGB_MEAN) / 127.5\n",
    "\n",
    "\n",
    "def denormalize(x):\n",
    "    return x * 127.5 + DIV2K_RGB_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "#send face(s) through super resolution network, (????? TODO, train on Colab, load here, find LR/SR face dataset as well)\n",
    "\n",
    "# EDSR baseline as described in the EDSR paper (1.52M parameters)\n",
    "model_edsr = edsr(scale=4, num_res_blocks=16)\n",
    "\n",
    "# Adam optimizer with a scheduler that halfs learning rate after 200,000 steps\n",
    "optim_edsr = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-4, 5e-5]))\n",
    "\n",
    "# Compile and train model for 300,000 steps with L1 pixel loss\n",
    "model_edsr.compile(optimizer=optim_edsr, loss='mean_absolute_error')\n",
    " \n",
    "model_edsr.load_weights('weights-edsr-40E.h5')\n",
    "\n",
    "import imageio\n",
    "im = imageio.imread('roi.png')\n",
    "\n",
    "y1 = model_edsr.predict(tf.reshape(tf.convert_to_tensor(im), [1,w,h,3]),steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "PIL_image = Image.fromarray(np.asarray(y1).reshape(156,156,3).astype('uint8'), 'RGB')\n",
    "\n",
    "PIL_image.save('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overlay big face on OG image: https://stackoverflow.com/questions/40895785/using-opencv-to-overlay-transparent-image-onto-another-image?fbclid=IwAR2FxAinlVh8GOKCZmQW0kZMOmAEt_caonwHTHPI3cDAiT3Yo-tJGTOmufs\n",
    "imageOG = cv2.imread(TEST_PHOTO)\n",
    "cv2.imwrite(\"combined.png\", imageOG)\n",
    "\n",
    "imageOG = cv2.imread(\"combined.png\")\n",
    "bigHead = cv2.imread(\"test.png\")\n",
    "\n",
    "rows,cols,channels = bigHead.shape\n",
    "\n",
    "imageOG[x-int((7/8)*rows):x-int((7/8)*rows)+rows, y-int((3/16)*cols):y-int((3/16)*cols)+cols] = bigHead #overlay\n",
    "cv2.imwrite('combined.png', imageOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cartoonify image and display\n",
    "#https://analyticsindiamag.com/converting-image-into-a-pencil-sketch-in-python/\n",
    "#OR\n",
    "#https://analyticsindiamag.com/converting-an-image-to-a-cartoon/?fbclid=IwAR1KsgK4sj3mpkUU-kIolQS1kUFnkkCo5bLDeq4BFPvfOzXRa-_gHF_PbWw\n",
    "\n",
    "combined = cv2.imread(\"combined.png\")\n",
    "img_gray = cv2.cvtColor(combined, cv2.COLOR_BGR2GRAY)\n",
    "img_invert = cv2.bitwise_not(img_gray)\n",
    "img_smoothing = cv2.GaussianBlur(img_invert, (31, 31),sigmaX=0, sigmaY=0)\n",
    "\n",
    "def dodgeV2(x, y):\n",
    "    return cv2.divide(x, 255 - y, scale=256)\n",
    "\n",
    "final_img = dodgeV2(img_gray, img_smoothing)\n",
    "\n",
    "cv2.imwrite('final.png', final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER ideas include changing what we big-ify, changing the background (to a touristy place) and the weather..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
