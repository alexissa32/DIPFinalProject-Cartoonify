{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SuperResolveFaces.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKJox-1n92t0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b1e53c-8ba8-4eea-c70b-5c5fef0591a0"
      },
      "source": [
        "#help from: http://krasserm.github.io/2019/09/04/super-resolution/ AND https://medium.com/beyondminds/an-introduction-to-super-resolution-using-deep-learning-f60aff9a499d\n",
        "\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "#file_id = 'REPLACE_WITH_YOUR_FILE_ID'\n",
        "#downloaded = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/Shared drives/Super Resolution Project\"\n",
        "#!ls \"/content/drive/Shared drives/Super Resolution Project/DIV2K_train_LR_x8\"\n",
        "#!ls \"/content/drive/Shared drives/Super Resolution Project/DIV2K_train_HR\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUYtdfPSM6Rq"
      },
      "source": [
        "#import imageio\n",
        "#import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuNqDKMXNSl6"
      },
      "source": [
        "'''\n",
        "hr_dir = \"/content/drive/Shareddrives/Super Resolution Project/1to5K/*.png\"\n",
        "lr_dir = \"/content/drive/Shareddrives/Super Resolution Project/1to5K3232/*.png\"\n",
        "\n",
        "lr = []\n",
        "hr = []\n",
        "for im_path in glob.glob(lr_dir):\n",
        "    #print(im_path)\n",
        "    im = imageio.imread(im_path)\n",
        "    lr.append(im)\n",
        "    #print(im)\n",
        "    #print(im.dtype)\n",
        "    #print(im.shape)\n",
        "    # do whatever with the image here\n",
        "\n",
        "for im_path in glob.glob(hr_dir):\n",
        "    #print(im_path)\n",
        "    im = imageio.imread(im_path)\n",
        "    hr.append(im)\n",
        "    #print(im.shape)\n",
        "    # do whatever with the image here\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yavohOoraIGD"
      },
      "source": [
        "import pickle\n",
        "\n",
        "lr = []\n",
        "with open(\"/content/drive/Shareddrives/Super Resolution Project/lrList\", 'rb') as fp:\n",
        "    lr = pickle.load(fp)\n",
        "\n",
        "hr = []\n",
        "with open(\"/content/drive/Shareddrives/Super Resolution Project/hrList\", 'rb') as fp:\n",
        "    hr = pickle.load(fp)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbMPZqIENaNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a0b67c75-9cf8-41e8-a5dd-6235d3445167"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(lr, hr, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "print(X_train.shape) \n",
        "#X_train = tf.reshape(X_train, [3780,3072]) #np.array(X_train).reshape(1,-1)\n",
        "#print(X_train.shape)\n",
        "\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "print(y_train.shape)\n",
        "#y_train = tf.reshape(y_train, [3780,49152]) #np.array(y_train).reshape(1,-1)\n",
        "#print(y_train.shape)\n",
        "\n",
        "X_test = tf.convert_to_tensor(X_test)#.reshape(1,-1)\n",
        "#X_test = tf.reshape(X_test, [1621,3072]) #np.array(y_train).reshape(1,-1)\n",
        "\n",
        "y_test = tf.convert_to_tensor(y_test)#.reshape(1,-1)\n",
        "#y_test = tf.reshape(y_test, [1621,49152]) #np.array(y_train).reshape(1,-1)\n",
        "\n",
        "'''\n",
        "X_train = np.array(X_train)\n",
        "print(X_train.shape) \n",
        "X_train = X_train.reshape(3780,-1) #np.array(X_train).reshape(1,-1)\n",
        "print(X_train.shape)\n",
        "#X_train = X_train.reshape(-1,3780,1024,3) #np.array(X_train).reshape(1,-1)\n",
        "#print(X_train.shape)\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "print(y_train.shape)\n",
        "y_train = y_train.reshape(3780,-1) #np.array(y_train).reshape(1,-1)\n",
        "print(y_train.shape)\n",
        "#y_train = y_train.reshape(-1,3780,16384,3) #np.array(y_train).reshape(1,-1)\n",
        "#print(y_train.shape)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "\n",
        "X_test = np.array(X_test)#.reshape(1,-1)\n",
        "X_test = X_test.reshape(1621,-1) #np.array(y_train).reshape(1,-1)\n",
        "#X_test = X_test.reshape(-1,1621,1024,3) #np.array(y_train).reshape(1,-1)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "\n",
        "y_test = np.array(y_test)#.reshape(1,-1)\n",
        "y_test = y_test.reshape(1621,-1) #np.array(y_train).reshape(1,-1)\n",
        "#y_test = y_test.reshape(-1,1621,16384,3) #np.array(y_train).reshape(1,-1)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3780, 32, 32, 3)\n",
            "(3780, 128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nX_train = np.array(X_train)\\nprint(X_train.shape) \\nX_train = X_train.reshape(3780,-1) #np.array(X_train).reshape(1,-1)\\nprint(X_train.shape)\\n#X_train = X_train.reshape(-1,3780,1024,3) #np.array(X_train).reshape(1,-1)\\n#print(X_train.shape)\\nX_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\\n\\ny_train = np.array(y_train)\\nprint(y_train.shape)\\ny_train = y_train.reshape(3780,-1) #np.array(y_train).reshape(1,-1)\\nprint(y_train.shape)\\n#y_train = y_train.reshape(-1,3780,16384,3) #np.array(y_train).reshape(1,-1)\\n#print(y_train.shape)\\ny_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\\n\\nX_test = np.array(X_test)#.reshape(1,-1)\\nX_test = X_test.reshape(1621,-1) #np.array(y_train).reshape(1,-1)\\n#X_test = X_test.reshape(-1,1621,1024,3) #np.array(y_train).reshape(1,-1)\\nX_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\\n\\ny_test = np.array(y_test)#.reshape(1,-1)\\ny_test = y_test.reshape(1621,-1) #np.array(y_train).reshape(1,-1)\\n#y_test = y_test.reshape(-1,1621,16384,3) #np.array(y_train).reshape(1,-1)\\ny_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AflTBA9-N07I"
      },
      "source": [
        "from tensorflow.keras.layers import Add, Conv2D, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
        "\n",
        "def edsr(scale, num_filters=64, num_res_blocks=8, res_block_scaling=None):\n",
        "    \"\"\"Creates an EDSR model.\"\"\"\n",
        "    x_in = Input(shape=(None, None, 3))\n",
        "    x = Lambda(normalize)(x_in)\n",
        "\n",
        "    x = b = Conv2D(num_filters, 3, padding='same')(x)\n",
        "    for i in range(num_res_blocks):\n",
        "        b = res_block(b, num_filters, res_block_scaling)\n",
        "    b = Conv2D(num_filters, 3, padding='same')(b)\n",
        "    x = Add()([x, b])\n",
        "\n",
        "    x = upsample(x, scale, num_filters)\n",
        "    x = Conv2D(3, 3, padding='same')(x)\n",
        "\n",
        "    x = Lambda(denormalize)(x)\n",
        "    return Model(x_in, x, name=\"edsr\")\n",
        "\n",
        "\n",
        "def res_block(x_in, filters, scaling):\n",
        "    \"\"\"Creates an EDSR residual block.\"\"\"\n",
        "    x = Conv2D(filters, 3, padding='same', activation='relu')(x_in)\n",
        "    x = Conv2D(filters, 3, padding='same')(x)\n",
        "    if scaling:\n",
        "        x = Lambda(lambda t: t * scaling)(x)\n",
        "    x = Add()([x_in, x])\n",
        "    return x\n",
        "\n",
        "\n",
        "def upsample(x, scale, num_filters):\n",
        "    def upsample_1(x, factor, **kwargs):\n",
        "        \"\"\"Sub-pixel convolution.\"\"\"\n",
        "        x = Conv2D(num_filters * (factor ** 2), 3, padding='same', **kwargs)(x)\n",
        "        return Lambda(pixel_shuffle(scale=factor))(x)\n",
        "\n",
        "    if scale == 2:\n",
        "        x = upsample_1(x, 2, name='conv2d_1_scale_2')\n",
        "    elif scale == 3:\n",
        "        x = upsample_1(x, 3, name='conv2d_1_scale_3')\n",
        "    elif scale == 4:\n",
        "        x = upsample_1(x, 2, name='conv2d_1_scale_2')\n",
        "        x = upsample_1(x, 2, name='conv2d_2_scale_2')\n",
        "\n",
        "    return x\n",
        "\n",
        "def pixel_shuffle(scale):\n",
        "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    return (x - DIV2K_RGB_MEAN) / 127.5\n",
        "\n",
        "\n",
        "def denormalize(x):\n",
        "    return x * 127.5 + DIV2K_RGB_MEAN"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh1kYdr6ZsDI"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LxgRbckYW9X"
      },
      "source": [
        "#import os\n",
        "\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "\n",
        "# Create directory for saving model weights\n",
        "#weights_dir = '/content/drive/Shareddrives/Super Resolution Project/'\n",
        "#os.makedirs(weights_dir, exist_ok=True)\n",
        "\n",
        "# EDSR baseline as described in the EDSR paper (1.52M parameters)\n",
        "#model_edsr = edsr(scale=4, num_res_blocks=16)\n",
        "\n",
        "# Adam optimizer with a scheduler that halfs learning rate after 200,000 steps\n",
        "#optim_edsr = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-4, 5e-5]))\n",
        "\n",
        "# Compile and train model for 300,000 steps with L1 pixel loss\n",
        "#model_edsr.compile(optimizer=optim_edsr, loss='mean_absolute_error')\n",
        "#model_edsr.fit(X_train, y_train, epochs=14, steps_per_epoch=32)\n",
        "\n",
        "# Save model weights\n",
        "#model_edsr.save_weights(os.path.join(weights_dir, 'weights-edsr-14E.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T44pbscq6Q36",
        "outputId": "ef3a05f2-664a-4e12-9840-f8e1f52b702d"
      },
      "source": [
        "# Create directory for saving model weights\n",
        "weights_dir = '/content/drive/Shareddrives/Super Resolution Project/'\n",
        "os.makedirs(weights_dir, exist_ok=True)\n",
        "\n",
        "# EDSR baseline as described in the EDSR paper (1.52M parameters)\n",
        "model_edsr = edsr(scale=4, num_res_blocks=16)\n",
        "\n",
        "# Adam optimizer with a scheduler that halfs learning rate after 200,000 steps\n",
        "optim_edsr = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[10000], values=[1e-4, 5e-5]))\n",
        "\n",
        "# Compile and train model for 300,000 steps with L1 pixel loss\n",
        "model_edsr.compile(optimizer=optim_edsr, loss='mean_absolute_error')\n",
        " \n",
        "model_edsr.load_weights('/content/drive/Shareddrives/Super Resolution Project/weights-edsr-25E.h5')\n",
        "\n",
        "model_edsr.fit(X_train, y_train, epochs=15, shuffle=True)\n",
        "\n",
        "# Save model weights\n",
        "model_edsr.save_weights(os.path.join(weights_dir, 'weights-edsr-40E.h5'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "119/119 [==============================] - 1161s 10s/step - loss: 7.8205\n",
            "Epoch 2/15\n",
            "119/119 [==============================] - 1154s 10s/step - loss: 7.6887\n",
            "Epoch 3/15\n",
            "119/119 [==============================] - 1157s 10s/step - loss: 7.6215\n",
            "Epoch 4/15\n",
            "119/119 [==============================] - 1160s 10s/step - loss: 7.5563\n",
            "Epoch 5/15\n",
            "119/119 [==============================] - 1161s 10s/step - loss: 7.5103\n",
            "Epoch 6/15\n",
            "119/119 [==============================] - 1158s 10s/step - loss: 7.4421\n",
            "Epoch 7/15\n",
            "119/119 [==============================] - 1154s 10s/step - loss: 7.3934\n",
            "Epoch 8/15\n",
            "119/119 [==============================] - 1160s 10s/step - loss: 7.3441\n",
            "Epoch 9/15\n",
            "119/119 [==============================] - 1159s 10s/step - loss: 7.3024\n",
            "Epoch 10/15\n",
            "119/119 [==============================] - 1165s 10s/step - loss: 7.2671\n",
            "Epoch 11/15\n",
            "119/119 [==============================] - 1157s 10s/step - loss: 7.2199\n",
            "Epoch 12/15\n",
            "119/119 [==============================] - 1161s 10s/step - loss: 7.1980\n",
            "Epoch 13/15\n",
            "119/119 [==============================] - 1162s 10s/step - loss: 7.1516\n",
            "Epoch 14/15\n",
            "119/119 [==============================] - 1155s 10s/step - loss: 7.1197\n",
            "Epoch 15/15\n",
            "119/119 [==============================] - 1159s 10s/step - loss: 7.1006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXl4rtbMcsLK"
      },
      "source": [
        "# Save model weights\n",
        "#model_edsr.save_weights(os.path.join('/content/drive/Shareddrives/Super Resolution Project/', 'weights-edsr-16-x4-8Epochs.h5'))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm_8QGirp3-B"
      },
      "source": [
        "# Create directory for saving model weights\n",
        "weights_dir = '/content/drive/Shareddrives/Super Resolution Project/'\n",
        "os.makedirs(weights_dir, exist_ok=True)\n",
        "\n",
        "# EDSR baseline as described in the EDSR paper (1.52M parameters)\n",
        "model_edsr = edsr(scale=4, num_res_blocks=16)\n",
        "\n",
        "# Adam optimizer with a scheduler that halfs learning rate after 200,000 steps\n",
        "#optim_edsr = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-4, 5e-5]))\n",
        "\n",
        "# Compile and train model for 300,000 steps with L1 pixel loss\n",
        "#model_edsr.compile(optimizer=optim_edsr, loss='mean_absolute_error')\n",
        " \n",
        "model_edsr.load_weights('/content/drive/Shareddrives/Super Resolution Project/weights-edsr-40E.h5')\n",
        "\n",
        "y1 = model_edsr.predict(tf.reshape(tf.convert_to_tensor(X_test[0]), [1,32,32,3]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fqaX2YsrA6u"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "PIL_image = Image.fromarray(np.asarray(y1).reshape(128,128,3).astype('uint8'), 'RGB')\n",
        "\n",
        "PIL_image.save('test.png')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdmBdm-3sNA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}